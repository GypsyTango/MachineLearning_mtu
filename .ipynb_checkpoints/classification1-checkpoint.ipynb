{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Project 1- Group 1: Chen Lou, James McNally & Josef Pishek\n",
    "\n",
    "3/2/2020\n",
    "\n",
    "For this assignment we will implement several KNN classifiers on the MNIST data set. \n",
    "\n",
    "We downloaded the MNIST data set from http://yann.lecun.com/exdb/mnist/. There is a training data set and a test data set. Each image is 28x28 pixels.\n",
    "\n",
    "Aside from the associated intructions to load the data, we found the following resources useful for visualizing MNIST data, and creating a model with leave-one-out cross validation. \n",
    "\n",
    "https://github.com/ibodumas/naivebayes_mnist/blob/master/Classification_MNIST_NaiveBayes.ipynb\n",
    "\n",
    "https://github.com/nmolivo/Blogs/blob/master/001_LOOCV/blog_001-LOOCV.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, gzip, shutil, codecs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import prettytable\n",
    "import skimage.measure\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "import math\n",
    "from sklearn import neighbors, metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from prettytable import PrettyTable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Extract and convert ubyte data to numpy array #####\n",
    "We will setup a `path_in` that contains the .gz files, and a `path_out` to put the extracted files into. Then we iterate over the files and capture the ubyte information and naming convention. We then export the image data to a dictionary. When importing and converting data, we use an 8-bit integer to reduce the size of the array. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/clou/Desktop/git_control/mtu_ml_proj_team/classification/classification1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "unzip and load data\n",
    "\n",
    "\"\"\"\n",
    "path_in = os.getcwd()+'/raw_data/'\n",
    "path_out = os.getcwd()+'/extracted/'\n",
    "files_in = os.listdir(path_in)\n",
    "files_out = os.listdir(path_out)\n",
    "# print(\"original data: \", files_in)\n",
    "    \n",
    "for file in files_in:\n",
    "    if file.endswith('gz'):\n",
    "        with gzip.open(path_in + file, mode='rb') as f_in:\n",
    "            with open(path_out + file.split('.')[0], mode='wb') as f_out:\n",
    "                shutil.copyfileobj(f_in, f_out)\n",
    "                files_out = os.listdir(path_out)\n",
    "\n",
    "                \n",
    "\"\"\"\n",
    "convert ubyte file to numpy array\n",
    "\n",
    "32 bits = 4 bytes\n",
    "offset 0-3: magic number { 2049 is label file ; 2051 is image file }\n",
    "offset 4-7: array length\n",
    "\n",
    "\n",
    "label file:\n",
    "\n",
    "offset 8:      label value (0-9)\n",
    "offset 9:      label value (0-9)\n",
    "offset ???:    label value (0-9)\n",
    "\n",
    "\n",
    "image file: \n",
    "\n",
    "offset 8-11:   number of rows\n",
    "offset 12-15:  number of columns\n",
    "offset 16:     1 pixel value \n",
    "offset 17:     1 pixel value\n",
    "offset ???:    1 pixel value \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "my_dic = {}\n",
    "for file1 in files_out:\n",
    "    if file1.endswith('ubyte'):\n",
    "        with open(path_out + file1, mode='rb') as f:\n",
    "            my_data = f.read()\n",
    "            # file type check\n",
    "            magic_num = int(codecs.encode(my_data[0:4], 'hex'), 16)\n",
    "            # file length check\n",
    "            num_len = int(codecs.encode(my_data[4:8], 'hex'), 16)\n",
    "            # print(num_len, magic_num)\n",
    "            # train len: 60000; test len: 10000 \n",
    "            if num_len == 10000:\n",
    "                length = 'test'\n",
    "            elif num_len == 60000:\n",
    "                length = 'train'\n",
    "                \n",
    "            if magic_num == 2049:\n",
    "                # start from offset 8, convert one label to an integer each time\n",
    "                lab = np.frombuffer(my_data, np.uint8, offset=8)\n",
    "                parse = lab.reshape(num_len)\n",
    "                # print(lab)\n",
    "                cat = 'label'\n",
    "            elif magic_num == 2051:\n",
    "                # rows from offset 8 - 11\n",
    "                rows = int(codecs.encode(my_data[8:12], 'hex'), 16)\n",
    "                # colmns from offset 12 - 15\n",
    "                cols = int(codecs.encode(my_data[12:16], 'hex'), 16)\n",
    "                # start from offset 16, convert one pixel to an integer each time\n",
    "                pix = np.frombuffer(my_data, np.uint8, offset=16)\n",
    "                parse = pix.reshape(num_len, rows, cols)\n",
    "                cat = 'image'\n",
    "            \n",
    "            my_dic[cat + '_' + length] = parse\n",
    "\n",
    "print(my_dic.keys())\n",
    "# print('image_test shape: ' + str(my_dic['image_test'].shape))\n",
    "# print('label_test shape: ' + str(my_dic['label_test'].shape))\n",
    "# print('image_train shape: ' + str(my_dic['image_train'].shape))\n",
    "# print('label_train shape: ' + str(my_dic['label_train'].shape))\n",
    "# # my_dic['label_test']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can set up our testing and training data from our image dictionary for both the data, X, and target/response/classification, y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape arrays by flattening 28x28 image into a 784 dimension vector\n",
    "X_train, y_train = my_dic['image_train'].reshape(60000, 28*28), my_dic['label_train']\n",
    "X_test, y_test = my_dic['image_test'].reshape(10000, 28*28), my_dic['label_test']\n",
    "print('X_train shape: ' + str(X_train.shape))\n",
    "print('X_test shape: ' + str(X_test.shape))\n",
    "print('y_train shape: ' + str(y_train.shape))\n",
    "print('y_test shape: ' + str(y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### i) (10 pts) Implement a 1-nearest neighbor classifier that considers the image pixels to be one long feature vector. The vector will be 28*28 = 784-dimensions long (one feature for each pixel in the image). Do not do any scaling or normalization on the pixel values. Present the testing error for each digit in a table.\n",
    "Because the leave-one-out cross validation is so computationally expensive, yet highly accurate, we will take a random sample of 2000 images from the training dataset to complete the following analysis. The index will be stored in `randindex` so that we can ensure we use the same data across each model. We can also check to make sure our target, labels, have relatively equal frequencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.RandomState(200)\n",
    "randindex=np.random.randint(len(X_train),size=2000)\n",
    "print('Random Index of length ' +str(len(randindex))+':')\n",
    "print(randindex)\n",
    "target=y_train[randindex]\n",
    "unique, counts = np.unique(target, return_counts=True)\n",
    "print('Frequency of Training Labels:')\n",
    "print(np.asarray((unique, counts)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can quickly fit a single nearest neighbors classifier and test it on the first 1000 images from the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fitting\n",
    "knn = neighbors.KNeighborsClassifier(n_neighbors = 1)\n",
    "knn.fit(X_train[randindex],y_train[randindex])\n",
    "# prediction on first 1000 points from test dataset\n",
    "y_pred = knn.predict(X_test[1:1000])\n",
    "# comfusion matrix\n",
    "cm = confusion_matrix(y_pred, y_test[1:1000])\n",
    "# print(c)\n",
    "# print(c.sum(axis=0)) # sum of each col\n",
    "# print(c.sum(axis=1)) # sum of each row\n",
    "# print(np.diag(c))\n",
    "\"\"\"\n",
    "tp: true positive  |  tn: true negative  | fp: false positive  | fn: false negative\n",
    "accuracy = tp + tn / (tp + tn + fp + fn)\n",
    "test_error = 1- accuracy\n",
    "\n",
    "\"\"\"\n",
    "def test_error_table(tp, fp, fn, tn):\n",
    "    accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "    test_error = 1 - accuracy\n",
    "    test_error = test_error.tolist()\n",
    "    \n",
    "    # make a table \n",
    "    round_test_error = [ round(i, 5) for i in test_error ]\n",
    "    PT = PrettyTable([\"k_value\\label\", \"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"])\n",
    "    \n",
    "    PT.add_row([1] + round_test_error)\n",
    "    return print(PT)\n",
    "\n",
    "\n",
    "# call the test_error table\n",
    "tp = np.diag(cm).astype(float)\n",
    "fp = (cm.sum(axis=0)-tp).astype(float)\n",
    "fn = (cm.sum(axis=1)-tp).astype(float)\n",
    "tn = (cm.sum() - tp - fp - fn).astype(float)\n",
    "\n",
    "test_error_table(tp, fp, fn, tn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ii) (10 pts) Implement a KNN leave-one-out approach and test values of K from 1 to 20. Plot the leave-one-out error vs. K. Present the testing error for best value of K for each digit in a table. (If you are running into time problems using all 60,000 data points for leave-one-out, feel free to randomly sample the training set to estimate the best K.)\n",
    "\n",
    "Taking what we learned from the previous model, which performed well (under 3.1% error for each digit), we can create a function that gives us the testing error for each value of K, cross validated using the leave-one-out (LOO) method. So essentially, for each value of K we will compute the LOO error. The LOO error is calculated by re-training the KNN classifier on the entire training set, except for one image which we test our prediction on. So this loop happens 2000 times, to yield 2000 predictions that we can compute the error from the truth. Since we are using the sklearn `KNeighborsClassifier(n_neighbors = k)` function, this LOO will take a long time since the distance matrix that is used to find the K-nearest neighbors is recomputed for each of the 2000 cross validation folds. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def Leave_one_out_error(X, y, K):\n",
    "    # print(X.shape)\n",
    "    # print(y.shape)\n",
    "    ytests = []\n",
    "    ypreds = []\n",
    "    err_list = []\n",
    "    for k in K:    \n",
    "        model = neighbors.KNeighborsClassifier(n_neighbors = k)\n",
    "        loo = sklearn.model_selection.LeaveOneOut()\n",
    "        for train_idx, test_idx in loo.split(X):\n",
    "            X_train_loo, X_test_loo = X[train_idx], X[test_idx] # requires arrays\n",
    "            y_train_loo, y_test_loo = y[train_idx], y[test_idx]\n",
    "            model.fit(X = X_train_loo, y = y_train_loo)\n",
    "            y_pred = model.predict(X_test_loo)\n",
    "\n",
    "            # there is only one y-test and y-pred per iteration over the loo.split, \n",
    "            # so to get a proper graph, we append them to respective lists.\n",
    "\n",
    "            ytests += list(y_test_loo)\n",
    "            ypreds += list(y_pred)\n",
    "\n",
    "        acc = metrics.accuracy_score(ytests, ypreds)  \n",
    "        err = round(1-acc, 5)\n",
    "        err_list.append(err)\n",
    "\n",
    "    return err_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this function, we can compute our models on the requested training set rather quickly. We will present the LOO error table in the form of a plot because it easier to read and visualize as K changes. The best K chosen from the minimum error value will be presented with the plot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign the dimensions of training image, training label, and the K-value\n",
    "X = X_train[randindex,:]\n",
    "y = y_train[randindex]\n",
    "K = range(1,21)\n",
    "loo_err = Leave_one_out_error(X, y, K)\n",
    "\n",
    "# Plot leave-one-out error VS K-value \n",
    "plt.plot(K, loo_err)\n",
    "plt.ylabel('Leave-one-out error')\n",
    "plt.xlabel('K-value')\n",
    "plt.suptitle('Leave-One-Out error VS K-value')\n",
    "\n",
    "print('Best Error value: '+str(min(loo_err)))\n",
    "print('at K-value: '+str(loo_err.index(min(loo_err))+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that we found the best K-value, so we should look at how the prediction error was across each value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Loo_table(X, y, K):\n",
    "    # print(X.shape)\n",
    "    # print(y.shape)\n",
    "    ytests = []\n",
    "    ypreds = []   \n",
    "    model = neighbors.KNeighborsClassifier(n_neighbors = K)\n",
    "    loo = sklearn.model_selection.LeaveOneOut()\n",
    "    for train_idx, test_idx in loo.split(X):\n",
    "        X_train_loo, X_test_loo = X[train_idx], X[test_idx]\n",
    "        y_train_loo, y_test_loo = y[train_idx], y[test_idx]\n",
    "        model.fit(X = X_train_loo, y = y_train_loo)\n",
    "        y_pred = model.predict(X_test_loo)\n",
    "\n",
    "        ytests += list(y_test_loo)\n",
    "        ypreds += list(y_pred)\n",
    "\n",
    "    cm = confusion_matrix(ytests, ypreds)\n",
    "    tp = np.diag(cm).astype(float)\n",
    "    fp = (cm.sum(axis=0)-tp).astype(float)\n",
    "    fn = (cm.sum(axis=1)-tp).astype(float)\n",
    "    tn = (cm.sum() - tp - fp - fn).astype(float)\n",
    "\n",
    "    test_error_table(tp, fp, fn, tn)\n",
    "\n",
    "    return test_error_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k = 7 gives the lowest error\n",
    "X = X_train[randindex,:]\n",
    "y = y_train[randindex]\n",
    "K = loo_err.index(min(loo_err))+1\n",
    "Loo_table(X, y, K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that with K=7, we find similar errors for each digit, with '9' as the highest with a 3.4% error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### iii) (20 pts) Implement a function that downsamples the image by a factor of n. For example, if n is 4 then you will sample every 4th pixel (feature) in the 784-dimension feature vector. Repeat the KNN leave-one-out experiment with at least 4 different values of n. Comment on the testing results and the query time of the classifier.\n",
    "\n",
    "The last problem took a considerable amount of time, even with only 2000 images. Downsampling can improve our computational efficiency by reducing the number in our 784-dimension feature vector. We can sample every nth value from an array of flattened images using simple index slicing. We can implement this as a function called `nDownsample(array, n)` and test on our flattened `X_train` images by sampling every 4th, or nth, pixel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nDownsample(array, n):\n",
    "    downsample=(array[:,::n])\n",
    "    return downsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Original X_train: '+str(X_train.shape))\n",
    "X_train_ndown = nDownsample(X_train,4)\n",
    "print('Downsampled X_train: '+str(X_train_ndown.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This greatly reduces the a feature vector to just dimension/n, so 784/4=196. We can see how this affects our testing results and query time by varying the downsampling size, n. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_values = [2,4,7,14]\n",
    "for i in n_values:\n",
    "    X_train_ndown = nDownsample(X_train,i)\n",
    "    X_test_ndown = nDownsample(X_test,i)\n",
    "    # Assign the dimensions of training image, training label, and the K-value\n",
    "    X = X_train_ndown[randindex,:]\n",
    "    y = y_train[randindex]\n",
    "    K = range(1,21)\n",
    "    loo_err = Leave_one_out_error(X, y, K)\n",
    "\n",
    "    # Plot leave-one-out error VS K-value \n",
    "    plt.plot(K, loo_err)\n",
    "    plt.ylabel('Leave-one-out error')\n",
    "    plt.xlabel('K-value')\n",
    "    plt.suptitle('n-Downsampled Leave-One-Out error VS K-value')\n",
    "    plt.show()\n",
    "    print('For n: '+ str(i))\n",
    "    print('Best Error value: '+str(min(loo_err)))\n",
    "    print('at K-value: '+str(loo_err.index(min(loo_err))+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see slight computational improvement as n increases, however we also see our error get worse as n increases. This down sampling is gridded, and also blatantly removes values, so we should not expect any big accuracy improvements. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### iv) (20 pts) Implement a function that smart downsamples the image by binning nearby pixels. For example, if n is 4 then the 28x28 image will be binned down to a 7x7 image by summing each 4x4 block in the image. Repeat the KNN leave-one-out experiment with at least 4 different values of n. Comment on the testing results and the query time of the classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This smart downsampling came about in a discussion for SciKit's skimage package. We can use the function `block_reduce(image, block_size, func...)` to implement this. For example, we can use a block size of (4,4) and `np.sum` function as func. We will illustrate this with an image from our unflattened `my_dic['image_train']` array. \n",
    "\n",
    "https://github.com/scikit-image/scikit-image/issues/492\n",
    "https://scikit-image.org/docs/dev/api/skimage.measure.html?#block-reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "someImages = [0,1,2,3,4]\n",
    "fig, axs = plt.subplots(len(someImages),2, figsize=(15,30))\n",
    "plt.subplots_adjust(wspace=.001, hspace=.2)\n",
    "for index,image in enumerate(someImages):\n",
    "    image1 = my_dic['image_train'][image]\n",
    "    axs[index,0].imshow(image1, cmap='Greys_r')\n",
    "    axs[index,0].set_title('Original Image: '+str(my_dic['label_train'][image]))\n",
    "    image2=skimage.measure.block_reduce(my_dic['image_train'][image],(4,4),func=np.sum)\n",
    "    axs[index,1].imshow(image2, cmap='Greys_r')\n",
    "    axs[index,1].set_title('Smart Downsampled Image: '+str(my_dic['label_train'][image]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This type of downsampling is more intuitive in that it aggregates the pixels instead of outright removal. These images just appear at a lower resolution. We can now implement the `smartDownsample(image, n)` function to iterate over the entire image array, returning the smartly downsampled images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smartDownsample(images, n):\n",
    "    downsampled_images = np.empty((int(images.shape[0]),\n",
    "                                   int(images.shape[1]/n),\n",
    "                                   int(images.shape[2]/n)))\n",
    "    for index,image in enumerate(images):\n",
    "        down=skimage.measure.block_reduce(image,(n,n),func=np.sum)\n",
    "        downsampled_images[index] = down\n",
    "    return downsampled_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Original Training Array: \"+str(my_dic['image_train'].shape))\n",
    "image_train_down = smartDownsample(my_dic['image_train'],4)\n",
    "print(\"Smart Downsampled Training Array: \"+str(image_train_down.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will see how this more intuitively reduced size affects our performance and query time by repeating the loop from above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_values = [2,4,7,14]\n",
    "for i in n_values:\n",
    "    X_train_ndown = smartDownsample(my_dic['image_train'],i).reshape(60000, int((28/i)*(28/i)))\n",
    "    #print(X_train_ndown.shape)\n",
    "    X_test_ndown = smartDownsample(my_dic['image_test'],i).reshape(10000, int((28/i)*(28/i)))\n",
    "    #print(X_test_ndown.shape)\n",
    "    # Assign the dimensions of training image, training label, and the K-value\n",
    "    X = X_train_ndown[randindex,:]\n",
    "    y = y_train[randindex]\n",
    "    K = range(1,21)\n",
    "    loo_err = Leave_one_out_error(X, y, K)\n",
    "\n",
    "    # Plot leave-one-out error VS K-value \n",
    "    plt.plot(K, loo_err)\n",
    "    plt.ylabel('Leave-one-out error')\n",
    "    plt.xlabel('K-value')\n",
    "    plt.suptitle('Smart n-Downsampled Leave-One-Out error VS K-value')\n",
    "    plt.show()\n",
    "    print('For n: '+ str(i))\n",
    "    print('Best Error value: '+str(min(loo_err)))\n",
    "    print('at K-value: '+str(loo_err.index(min(loo_err))+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that our query speed increased with each increase in factor. But this time, we found a better error at n=2, K=6, and a very comparable error with n=4, K=7, before the error increased with higher factors (n). It might make sense, depending on where and how this model will be used to downsample if the slightly decreased accuracy is allowable. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### v) (10 pts) Run your smart downsampler at n = 28. Essentially, reduce each image down to 1 pixel by summing them all. The motivation here is that an '8' will obviously have more dark pixels than a '1' . Repeat the KNN leave-one-out experiment. Comment on the testing results and the query time of the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Original Training Array: \"+str(my_dic['image_train'].shape))\n",
    "image_train_down = smartDownsample(my_dic['image_train'],28)\n",
    "print(\"Smart Downsampled Training Array: \"+str(image_train_down.shape))\n",
    "X_train_ndown = smartDownsample(my_dic['image_train'],28).reshape(60000, 1)\n",
    "# Assign the dimensions of training image, training label, and the K-value\n",
    "X = X_train_ndown[randindex,:]\n",
    "y = y_train[randindex]\n",
    "K = range(1,40)\n",
    "loo_err = Leave_one_out_error(X, y, K)\n",
    "\n",
    "# Plot leave-one-out error VS K-value \n",
    "plt.plot(K, loo_err)\n",
    "plt.ylabel('Leave-one-out error')\n",
    "plt.xlabel('K-value')\n",
    "plt.suptitle('Single Pixel Leave-One-Out error VS K-value')\n",
    "plt.show()\n",
    "\n",
    "print('Best Error value: '+str(min(loo_err)))\n",
    "print('at K-value: '+str(loo_err.index(min(loo_err))+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the computational time was very fast, however the error is very high for this model. This is probably due to the variation in stroke width or thickness across all digits, depending on who is writing it. Interestingly, it required a large number of neighbors to really see the optimal K-value. This model needs a lot of bias to perform well, perhaps because the high bias introduced by downsampling so severely."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### vi) (30 pts) Do a little research of your own and develop a feature transformation method that you then use with the KNN leave-one-out experiment. Describe your method in detail, using equations and figures as necessary. Someone should be able to reproduce your results with your description. Comment on the testing results and the query time of the classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can first try implementing a PCA transformation on the data. This was suggested through discussion among peers to reduce the effect of rotation from handwriting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca=PCA()\n",
    "X_train_pca = pca.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "someImages = [0,1,2,3,4]\n",
    "fig, axs = plt.subplots(len(someImages),2, figsize=(15,30))\n",
    "plt.subplots_adjust(wspace=.001, hspace=.2)\n",
    "for index,image in enumerate(someImages):\n",
    "    image1 = my_dic['image_train'][image]\n",
    "    axs[index,0].imshow(image1, cmap='Greys_r')\n",
    "    axs[index,0].set_title('Original Image: '+str(my_dic['label_train'][image]))\n",
    "    image2=np.reshape(X_train_pca[image,:], (28,28))\n",
    "    axs[index,1].imshow(image2, cmap='Greys_r')\n",
    "    axs[index,1].set_title('PCA Transformed Array: '+str(y_train[image]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is clear that the pixels are no longer interpretable by the human eye, but different digits certainly show different encodings of the higher ranked principle components. This unsupervised method maximizes the variance between components to increase accuracy, but without setting a threshold and removing seemingly unimportant components, we won't see any computational gains. \n",
    "\n",
    "What if we downsampled by some factor before doing PCA? We found strong results by smart downsampling with a factor of n=2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 2\n",
    "X_train_ndown = smartDownsample(my_dic['image_train'],i).reshape(60000, int((28/i)*(28/i)))\n",
    "print(X_train_ndown.shape)\n",
    "pca=PCA()\n",
    "X_train_ndown_pca = pca.fit_transform(X_train_ndown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "someImages = [0,1,2,3,4]\n",
    "fig, axs = plt.subplots(len(someImages),2, figsize=(15,30))\n",
    "plt.subplots_adjust(wspace=.001, hspace=.2)\n",
    "for index,image in enumerate(someImages):\n",
    "    image1 = my_dic['image_train'][image]\n",
    "    axs[index,0].imshow(image1, cmap='Greys_r')\n",
    "    axs[index,0].set_title('Original Image: '+str(my_dic['label_train'][image]))\n",
    "    shp = int(math.sqrt(X_train_ndown_pca.shape[1]))\n",
    "    image2=np.reshape(X_train_ndown_pca[image,:], (shp,shp))\n",
    "    axs[index,1].imshow(image2, cmap='Greys_r')\n",
    "    axs[index,1].set_title('Downsampled PCA Transformed Array: '+str(y_train[image]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that about half the image shows any type of meaningful information as numbers change, so we will plan on retaining 98 out of 196 principal components for the training features. We can test our new training data the same way as before. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign the dimensions of training image, training label, and the K-value\n",
    "X = X_train_ndown_pca[randindex,0:98]\n",
    "y = y_train[randindex]\n",
    "K = range(1,21)\n",
    "loo_err = Leave_one_out_error(X, y, K)\n",
    "\n",
    "# Plot leave-one-out error VS K-value \n",
    "plt.plot(K, loo_err)\n",
    "plt.ylabel('Leave-one-out error')\n",
    "plt.xlabel('K-value')\n",
    "plt.suptitle('Smart Downsampled PCA Leave-One-Out error VS K-value')\n",
    "plt.show()\n",
    "\n",
    "print('Best Error value: '+str(min(loo_err)))\n",
    "print('at K-value: '+str(loo_err.index(min(loo_err))+1))"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our results seem to be slightly better, however there is no huge improvement, perhaps 0.2% less error. \n",
    "\n",
    "An additional feature transformation method that shows good results in this experiment is Linear Discriminant Analysis applied after Principal Component Analysis.\n",
    "Linear Discriminant Analysis (LDA) is a supervised dimension reduction method that can find the best linear projection based on Fisher's discriminants such that two classes of samples are well separated.  The method is used to transform variable of one set into another smaller set.    Because the data is now transformed into a smaller set, the data distribution can achieve the objective of maximizing the between-class distance and minimizing the within-class distance.  In order to achieve this, two measures are introduced to all feature vectors: within-class scatter matrix (SW), where  N is the number of classes, ni the number of samples in the ith class, represents the jth sample of the ith class, and μi the mean of class and between-class scatter matrix (SB): where μall is the mean of all classes.  Below are the equations for both the between class and within class variance:\n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "Based on Fisher’s discriminants, the projection w that best separates the two classes should satisfy:   \n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "The standard LDA can be seriously degraded if there are a limited number of observations in comparison to the feature space.  To prevent this, we first perform a principal component analysis (PCA), which is then followed by LDA.  Although our dataset was reasonably large, we still found better results when employing this feature transformation method to just PCA.  In PCA, the shape and location of the original data sets changes when transformed to a new feature space. LDA does not change the location but only focuses on providing more separability between classes and then draw a decision region between the specified classes. \n",
    "\n",
    "https://arxiv.org/ftp/arxiv/papers/1204/1204.1177.pdf\n",
    "\n",
    "https://www.sciencedirect.com/science/article/abs/pii/S0031320304004066"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "lda=LinearDiscriminantAnalysis()\n",
    "\n",
    "X_train_lda = lda.fit_transform(X_train_pca[:,0:98], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "someImages = [0,1,2,3,4]\n",
    "fig, axs = plt.subplots(len(someImages),2, figsize=(15,30))\n",
    "plt.subplots_adjust(wspace=.001, hspace=.2)\n",
    "for index,image in enumerate(someImages):\n",
    "    image1 = my_dic['image_train'][image]\n",
    "    axs[index,0].imshow(image1, cmap='Greys_r')\n",
    "    axs[index,0].set_title('Original Image: '+str(my_dic['label_train'][image]))\n",
    "    shp = int(math.sqrt(X_train_lda.shape[1]))\n",
    "    image2=np.reshape(X_train_lda[image,:], (shp,shp))\n",
    "    axs[index,1].imshow(image2, cmap='Greys_r')\n",
    "    axs[index,1].set_title('PCA LDA Transformed Array Post PCA: '+str(y_train[image]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The images show some promising results, let us cross validate to find the best KNN model using the same sample from the transformed training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign the dimensions of training image, training label, and the K-value\n",
    "X = X_train_lda[randindex,:]\n",
    "y = y_train[randindex]\n",
    "K = range(1,41)\n",
    "loo_err = Leave_one_out_error(X, y, K)\n",
    "\n",
    "# Plot leave-one-out error VS K-value \n",
    "plt.plot(K, loo_err)\n",
    "plt.ylabel('Leave-one-out error')\n",
    "plt.xlabel('K-value')\n",
    "plt.suptitle('PCA LDA Leave-One-Out error VS K-value')\n",
    "plt.show()\n",
    "\n",
    "print('Best Error value: '+str(min(loo_err)))\n",
    "print('at K-value: '+str(loo_err.index(min(loo_err))+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We might also check to see if the there is any improvement by using our smart downsampled (factor of 2) PCA transformed data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_ndown_lda = lda.fit_transform(X_train_ndown_pca[:,0:98], y_train)\n",
    "# Assign the dimensions of training image, training label, and the K-value\n",
    "X = X_train_ndown_lda[randindex,:]\n",
    "y = y_train[randindex]\n",
    "K = range(1,41)\n",
    "loo_err = Leave_one_out_error(X, y, K)\n",
    "\n",
    "# Plot leave-one-out error VS K-value \n",
    "plt.plot(K, loo_err)\n",
    "plt.ylabel('Leave-one-out error')\n",
    "plt.xlabel('K-value')\n",
    "plt.suptitle('Smart Downsampled PCA LDA Leave-One-Out error VS K-value')\n",
    "plt.show()\n",
    "\n",
    "print('Best Error value: '+str(min(loo_err)))\n",
    "print('at K-value: '+str(loo_err.index(min(loo_err))+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results seem no better with the the LDA as compared to the 2 factor smart downsampling. The query timing of each is close with no discernable differences. \n",
    "\n",
    "The best method we are able to show with the `randindex` sample (2500 images) of the image set seems to be 2 factor smart downsampling the data using `skimage.block_reduce()`, then performing a PCA transformation retaining half the components, which we trained with leave-one-out cross validation a 6-nearest neighbor classifier. \n",
    "\n",
    "We can validate our model on the first 1000 images from the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform X_test data\n",
    "i = 2\n",
    "X_test_ndown = smartDownsample(my_dic['image_test'],i).reshape(10000, int((28/i)*(28/i)))\n",
    "X_test_ndown_pca = pca.transform(X_test_ndown)\n",
    "# Assign the dimensions of training image, training label, and the K-value\n",
    "X = X_train_ndown_pca[randindex,0:98]\n",
    "y = y_train[randindex]\n",
    "# fitting\n",
    "knn = neighbors.KNeighborsClassifier(n_neighbors = 6)\n",
    "knn.fit(X,y)\n",
    "\n",
    "# prediction on first 1000 points from test dataset\n",
    "y_pred = knn.predict(X_test_ndown_pca[0:1000,0:98])\n",
    "# comfusion matrix\n",
    "acc = metrics.accuracy_score(y_test[0:1000], y_pred)  \n",
    "err = round(1-acc, 5)\n",
    "print('Error: '+str(err))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This validates our thinking that this is a good model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
